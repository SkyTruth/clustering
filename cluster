#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vim: set fileencoding=utf-8 :
# SETUPTOOLS_DO_NOT_WRAP

# cluster rows.csv clusters.csv
#
#  - Copyright (C) 2014 SkyTruth
#    Author: Egil Moeller <egil@skytruth.org>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

import numpy
import sklearn.cluster
import csv
import sys
import argparse


def floatify(row):
    res = {}
    for key in row:
        try:
            res[key] = float(row[key])
        except ValueError:
            pass
    return res

def loaddata(filename, maxlines=None):
    lines = -1
    with open(filename) as f:
         for l in f:
             lines += 1
             if maxlines is not None and lines >= maxlines: break

    with open(filename) as f:
        rows = csv.DictReader(f)

        X = numpy.zeros((lines, len(rows.fieldnames)))

        latlng = ['longitude', 'latitude']
        fieldnames = latlng + [name for name in rows.fieldnames
                               if name not in latlng]

        for idx, row in enumerate(rows):
            if idx >= lines: break

            for fieldidx, name in enumerate(fieldnames):
                try:
                    X[idx][fieldidx] = float(row[name])
                except ValueError:
                    X[idx][fieldidx] = float("nan")
    return fieldnames, X


parser = argparse.ArgumentParser(description='Process some integers.')
parser.add_argument('infile', metavar='FILE.csv', type=str, help='Input file')
parser.add_argument('outfile', metavar='FILE.csv', type=str, help='Output file')
parser.add_argument('--eps', metavar='N', type=float, default=0.013498916666666666,
                   help='eps')
parser.add_argument('--min_samples', metavar='N', type=int, default=3,
                   help='min_samples')

args = parser.parse_args(sys.argv[1:])

fieldnames, X = loaddata(args.infile)
db = sklearn.cluster.DBSCAN(eps=args.eps, min_samples=args.min_samples).fit(X[:,0:2])

with open(args.outfile, "w") as f:
    f = csv.writer(f)

    f.writerow([fieldname for fieldname in fieldnames]
               + [fieldname + "_stddev" for fieldname in fieldnames]
               + ['count'])
    for k in set(db.labels_):
        points = X[(db.labels_ == k).nonzero()]
        f.writerow([numpy.average(points[:,i]) for i in xrange(0, X.shape[1])]
                   + [numpy.std(points[:,i]) for i in xrange(0, X.shape[1])]
                   + [points.shape[0]])
